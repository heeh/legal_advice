{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXr-llCCp7_Z",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "906255c57419d",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "# Introduction\n",
    "* This program that classifies legal issues into a binary value for each National Subject Matter Index (NSMI). (https://nsmi.lsntap.org/browse-v2) \\\\\n",
    "\"Category\" means 20 indexes. \\\\\n",
    "\"Class\" means sub categories under the category.\n",
    "\n",
    "### Data\n",
    "* The data contains 2777 labeled articles. Each article has a binary value(0 or 1) that indicates if this article is related to a specific legal class. We ignore unlabeled entries when constructing a model.\n",
    "\n",
    "### Implementation\n",
    "* The program converts an article into tf-idf and applies multinomial Naive-Bayes model provided by scikit-learn. \n",
    "\n",
    "* After preprocessing data, we predict the model with 10-fold cross-validation.\n",
    "\n",
    "### Output\n",
    "* We calculate accuracy with bot categories(20) and classes(100+). \\\\\n",
    "\n",
    "See overall result is at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNIANhrjEzYE",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "c64b7d852eb46",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "# Data Preparation (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsbprkpElhDw",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "fbc1e35bd1c07",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PrettyTable in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: pandas in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: setuptools in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: seaborn in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from seaborn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from seaborn) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (41.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (4.43.0)\n",
      "Requirement already satisfied: nltk in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from nltk) (1.14.0)\n",
      "/Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package stopwords to /Users/heeh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/heeh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heeh/.pyenv/versions/3.8.0/lib/python3.8/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PrettyTable\n",
    "!pip3 install pandas\n",
    "!pip3 install sklearn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install tqdm\n",
    "!pip3 install nltk\n",
    "!python3 -m nltk.downloader stopwords punkt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "pd.options.display.max_rows = 100\n",
    "pd.set_option('display.max_columns', None) \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2953,
     "status": "ok",
     "timestamp": 1582551057054,
     "user": {
      "displayName": "Hee Hwang",
      "photoUrl": "",
      "userId": "05361436400321274076"
     },
     "user_tz": 300
    },
    "id": "6XZZPmUtlhGg",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "b4140f133d1e6",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    },
    "outputId": "161dab3f-ad00-4e8a-8bb5-99b9f7504581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2777 entries, 0 to 2776\n",
      "Columns: 109 entries, _id to WO-09-00-00-00\n",
      "dtypes: float64(107), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>BE-00-00-00-00</th>\n",
       "      <th>BE-01-00-00-00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b60e59cda52255c20cff794</td>\n",
       "      <td>Will he serve time?. Long story short my broth...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b60e59cda52255c20cff79a</td>\n",
       "      <td>Groundwater leaking out of street 24/7. Ground...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b60e59cda52255c20cff7a0</td>\n",
       "      <td>How do I get my mom's license taken away. My m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b60e59cda52255c20cff7bf</td>\n",
       "      <td>My boss hasn't paid me. What do i do?. I work ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b60e59cda52255c20cff7b8</td>\n",
       "      <td>[Texas] I signed a non-compete contract, but t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>5b60e66dda52255c20df433f</td>\n",
       "      <td>Do you and your parents get deported because o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>5b60e66dda52255c20df43ae</td>\n",
       "      <td>Wondering the legality of a minor (me) being a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>5b60e66dda52255c20df4462</td>\n",
       "      <td>Can I sue a billion dollar company in small cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>5b60e66dda52255c20df4448</td>\n",
       "      <td>Sued by creditor and currently in settlement n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>5b60e66dda52255c20df4491</td>\n",
       "      <td>(CA) Sales job. Income based on performance. A...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2777 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5b60e59cda52255c20cff794   \n",
       "1     5b60e59cda52255c20cff79a   \n",
       "2     5b60e59cda52255c20cff7a0   \n",
       "3     5b60e59cda52255c20cff7bf   \n",
       "4     5b60e59cda52255c20cff7b8   \n",
       "...                        ...   \n",
       "2772  5b60e66dda52255c20df433f   \n",
       "2773  5b60e66dda52255c20df43ae   \n",
       "2774  5b60e66dda52255c20df4462   \n",
       "2775  5b60e66dda52255c20df4448   \n",
       "2776  5b60e66dda52255c20df4491   \n",
       "\n",
       "                                              full_text  BE-00-00-00-00  \\\n",
       "0     Will he serve time?. Long story short my broth...             0.0   \n",
       "1     Groundwater leaking out of street 24/7. Ground...             0.0   \n",
       "2     How do I get my mom's license taken away. My m...             0.0   \n",
       "3     My boss hasn't paid me. What do i do?. I work ...             NaN   \n",
       "4     [Texas] I signed a non-compete contract, but t...             0.0   \n",
       "...                                                 ...             ...   \n",
       "2772  Do you and your parents get deported because o...             0.0   \n",
       "2773  Wondering the legality of a minor (me) being a...             0.0   \n",
       "2774  Can I sue a billion dollar company in small cl...             0.0   \n",
       "2775  Sued by creditor and currently in settlement n...             0.0   \n",
       "2776  (CA) Sales job. Income based on performance. A...             0.0   \n",
       "\n",
       "      BE-01-00-00-00  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                NaN  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "2772             0.0  \n",
       "2773             0.0  \n",
       "2774             0.0  \n",
       "2775             0.0  \n",
       "2776             0.0  \n",
       "\n",
       "[2777 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/heeh/legal_issue_classification/master/2019-12-06_95p-confidence_binary.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.info()\n",
    "df.iloc[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "1c9646a6871a5",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Null and Rowsum Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8575,
     "status": "ok",
     "timestamp": 1582551062684,
     "user": {
      "displayName": "Hee Hwang",
      "photoUrl": "",
      "userId": "05361436400321274076"
     },
     "user_tz": 300
    },
    "id": "LWh8RtxFlhKT",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "46f3ebdce3ec5",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    },
    "outputId": "8a2616da-2389-4142-c19a-4fadc1b86d66"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Null Check\n",
    "#df.isnull().sum()\n",
    "\n",
    "# Class Check - Remove every column that has zero sum. \n",
    "df = df.loc[:, df.sum(axis=0, skipna=True) != 0]\n",
    "temp = df.sum(axis = 0, skipna = True)\n",
    "\n",
    "\n",
    "#df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "6b5f506275a07",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "# Remove columns that have <10 positive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "da6bfdef8ea13",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "36\n",
      "['_id', 'full_text', 'BE-00-00-00-00', 'BU-00-00-00-00', 'CO-00-00-00-00', 'CR-00-00-00-00', 'CR-01-00-00-00', 'CR-04-00-00-00', 'CR-06-00-00-00', 'CR-10-00-00-00', 'ED-00-00-00-00', 'ES-00-00-00-00', 'ES-01-00-00-00', 'ES-03-00-00-00', 'FA-00-00-00-00', 'FA-05-00-00-00', 'FA-06-00-00-00', 'FA-07-00-00-00', 'GO-00-00-00-00', 'HE-00-00-00-00', 'HO-00-00-00-00', 'HO-06-00-00-00', 'HO-09-00-00-00', 'IM-00-00-00-00', 'MO-00-00-00-00', 'MO-02-00-00-00', 'MO-07-00-00-00', 'MO-10-00-00-00', 'RI-00-00-00-00', 'TO-00-00-00-00', 'TR-00-00-00-00', 'TR-01-00-00-00', 'TR-02-00-00-00', 'TR-03-00-00-00', 'TR-04-00-00-00', 'TR-05-00-00-00', 'WO-00-00-00-00', 'WO-03-00-00-00']\n",
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_id               5b60e59cda52255c20cff7945b60e59cda52255c20cff7...\n",
       "full_text         Will he serve time?. Long story short my broth...\n",
       "BE-00-00-00-00                                                   27\n",
       "BU-00-00-00-00                                                   93\n",
       "CO-00-00-00-00                                                  106\n",
       "CR-00-00-00-00                                                  302\n",
       "CR-01-00-00-00                                                   12\n",
       "CR-04-00-00-00                                                   13\n",
       "CR-06-00-00-00                                                   11\n",
       "CR-10-00-00-00                                                   11\n",
       "ED-00-00-00-00                                                   24\n",
       "ES-00-00-00-00                                                   78\n",
       "ES-01-00-00-00                                                   10\n",
       "ES-03-00-00-00                                                   13\n",
       "FA-00-00-00-00                                                  357\n",
       "FA-05-00-00-00                                                   10\n",
       "FA-06-00-00-00                                                   10\n",
       "FA-07-00-00-00                                                   41\n",
       "GO-00-00-00-00                                                   13\n",
       "HE-00-00-00-00                                                  122\n",
       "HO-00-00-00-00                                                  550\n",
       "HO-06-00-00-00                                                   34\n",
       "HO-09-00-00-00                                                   27\n",
       "IM-00-00-00-00                                                   36\n",
       "MO-00-00-00-00                                                  366\n",
       "MO-02-00-00-00                                                   12\n",
       "MO-07-00-00-00                                                   13\n",
       "MO-10-00-00-00                                                   11\n",
       "RI-00-00-00-00                                                   22\n",
       "TO-00-00-00-00                                                  230\n",
       "TR-00-00-00-00                                                  260\n",
       "TR-01-00-00-00                                                   22\n",
       "TR-02-00-00-00                                                   29\n",
       "TR-03-00-00-00                                                   17\n",
       "TR-04-00-00-00                                                   20\n",
       "TR-05-00-00-00                                                   31\n",
       "WO-00-00-00-00                                                  387\n",
       "WO-03-00-00-00                                                   10\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldCols = list(df.columns)\n",
    "print(len(oldCols))\n",
    "\n",
    "newCols = []\n",
    "for i,x in temp[2:].items():\n",
    "    if x >= 10:\n",
    "        newCols.append(i)\n",
    "        \n",
    "print(len(newCols))\n",
    "\n",
    "cols = oldCols[:2] + newCols\n",
    "\n",
    "print(cols)\n",
    "print(len(cols))\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df.sum(axis=0, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zB9yYBXlrN7p",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "8f56427cc56eb",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "# Tiny Example: Crime and Prison(CR-00-00-00-00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoY-GYaJeHkk",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "cf617134b9c83",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Preprocessing (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8562,
     "status": "ok",
     "timestamp": 1582551062685,
     "user": {
      "displayName": "Hee Hwang",
      "photoUrl": "",
      "userId": "05361436400321274076"
     },
     "user_tz": 300
    },
    "id": "8WqotY32rOEs",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "455af60adbcad",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    },
    "outputId": "b16f4dc2-bb9c-43d8-ad00-083a13c9b77e"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "verbose = True\n",
    "def preprocessing(dfset: defaultdict, cls: str):\n",
    "    dfset[cls] = df.loc[:, ['_id', 'full_text', cls]]\n",
    "    labels = dfset[cls].iloc[:,2]\n",
    "    if verbose:\n",
    "        print(\"------------Before dropping nan----------------------------------------\")\n",
    "        print(dfset[cls].iloc[:,1:])\n",
    "        print(labels.value_counts(dropna=False))\n",
    "    \n",
    "    dfset[cls] = dfset[cls].dropna()\n",
    "    labels = dfset[cls].iloc[:,2]\n",
    "    if verbose:\n",
    "        print(\"\\n------------After dropping nan---------------------------------------\")\n",
    "        print(dfset[cls].iloc[:,1:])\n",
    "        print(labels.value_counts(dropna=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "11459136fca6",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "11e5448bf4137",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Before dropping nan----------------------------------------\n",
      "                                              full_text  CR-00-00-00-00\n",
      "0     Will he serve time?. Long story short my broth...             1.0\n",
      "1     Groundwater leaking out of street 24/7. Ground...             0.0\n",
      "2     How do I get my mom's license taken away. My m...             NaN\n",
      "3     My boss hasn't paid me. What do i do?. I work ...             0.0\n",
      "4     [Texas] I signed a non-compete contract, but t...             0.0\n",
      "...                                                 ...             ...\n",
      "2772  Do you and your parents get deported because o...             1.0\n",
      "2773  Wondering the legality of a minor (me) being a...             0.0\n",
      "2774  Can I sue a billion dollar company in small cl...             0.0\n",
      "2775  Sued by creditor and currently in settlement n...             0.0\n",
      "2776  (CA) Sales job. Income based on performance. A...             0.0\n",
      "\n",
      "[2777 rows x 2 columns]\n",
      "0.0    1377\n",
      "NaN    1098\n",
      "1.0     302\n",
      "Name: CR-00-00-00-00, dtype: int64\n",
      "\n",
      "------------After dropping nan---------------------------------------\n",
      "                                              full_text  CR-00-00-00-00\n",
      "0     Will he serve time?. Long story short my broth...             1.0\n",
      "1     Groundwater leaking out of street 24/7. Ground...             0.0\n",
      "3     My boss hasn't paid me. What do i do?. I work ...             0.0\n",
      "4     [Texas] I signed a non-compete contract, but t...             0.0\n",
      "6     Eviction. I got an eviction notice from my lan...             0.0\n",
      "...                                                 ...             ...\n",
      "2772  Do you and your parents get deported because o...             1.0\n",
      "2773  Wondering the legality of a minor (me) being a...             0.0\n",
      "2774  Can I sue a billion dollar company in small cl...             0.0\n",
      "2775  Sued by creditor and currently in settlement n...             0.0\n",
      "2776  (CA) Sales job. Income based on performance. A...             0.0\n",
      "\n",
      "[1679 rows x 2 columns]\n",
      "0.0    1377\n",
      "1.0     302\n",
      "Name: CR-00-00-00-00, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cls = 'CR-00-00-00-00'\n",
    "dfset = defaultdict() \n",
    "preprocessing(dfset, cls)    \n",
    "\n",
    "#    model[cls] = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "tinydf = dfset[cls]\n",
    "X = tinydf['full_text'].values\n",
    "Y = tinydf[cls].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "c3f6dd86ac10d",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## TF-IDF using stopwords, ngram, and C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "722be740702ee",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9148\n",
      "precision: 0.6333\n",
      "recall   : 0.8261\n",
      "fscore   : 0.7170\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n",
      "TF-IDF Dimension:  127258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "p = len(X) // 10 * 9\n",
    "#tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=300 )\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.3)\n",
    "tfidf_vect.fit(X[0:p])\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X[0:p])\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X[p:])\n",
    "\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced')\n",
    "model.fit(X_train_tfidf_vect, Y[0:p])\n",
    "preds = model.predict(X_test_tfidf_vect)\n",
    "precision, recall, fscore, support = score(Y[p:], preds, average='binary')\n",
    "print('accuracy : {0:.4f}'.format(accuracy_score(Y[p:], preds)))\n",
    "print('precision: {0:.4f}'.format(precision))\n",
    "print('recall   : {0:.4f}'.format(recall))\n",
    "print('fscore   : {0:.4f}'.format(fscore))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C':[0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(model,param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, Y[:p])\n",
    "print(grid_cv_lr.best_params_)\n",
    "\n",
    "print(\"TF-IDF Dimension: \", len(tfidf_vect.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "ce9f4cfe845d9",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## TF-IDF Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "a2c6503ce54bd",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy: 0.9147727272727273\n",
      "precision: [0.97260274 0.63333333]\n",
      "recall: [0.92810458 0.82608696]\n",
      "fscore: [0.94983278 0.71698113]\n",
      "support: [153  23]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = defaultdict()\n",
    "model = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.3)),\n",
    "    ('lr_clf', LogisticRegression(penalty='l1', solver='liblinear',class_weight='balanced'))\n",
    "])\n",
    "p = len(X) // 10 * 9\n",
    "\n",
    "model.fit(X[0:p], Y[0:p])\n",
    "preds = model.predict(X[p:])\n",
    "print(preds)\n",
    "accuracy = accuracy_score(Y[p:], preds)\n",
    "precision, recall, fscore, support = score(Y[p:], preds)\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "8dd4a61345312",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "source": [
    "## TF-IDF + Logistic Regression on CR-00-00-00-00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "92abe0eecdd5d",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1377\n",
      "1.0     302\n",
      "Name: CR-00-00-00-00, dtype: int64\n",
      "data set size 1679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8886, 0.6667, 0.7616, 0.711, 302)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "verbose = False\n",
    "    \n",
    "numdoc = defaultdict()\n",
    "\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced')\n",
    "\n",
    "\n",
    "def predict_by_class_tfidf(dfset: defaultdict,cls: str) -> float:\n",
    "    preprocessing(dfset, cls)\n",
    "    tinydf = dfset[cls]\n",
    "    X = tinydf['full_text'].values\n",
    "    Y = tinydf[cls].values\n",
    "    \n",
    "\n",
    "    print('------------------------------------\\n')\n",
    "    labels = dfset[cls].iloc[:,2]\n",
    "    print(labels.value_counts(dropna=False))\n",
    "\n",
    "    # 10-fold separation with train and test \n",
    "    #kfold = KFold(n_splits=10)\n",
    "    kfold = KFold(n_splits=10)\n",
    "    print('data set size', len(X))\n",
    "    numdoc[cls] = len(X)\n",
    "    n_iter = 0\n",
    "    acc_list = []\n",
    "    pre_list = []\n",
    "    rec_list = []\n",
    "    fsc_list = []\n",
    "    sup_list = []\n",
    "\n",
    "    \n",
    "    preds = [0] * len(Y)\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        Y_train, Y_test = Y[train_index], Y[test_index] \n",
    "        \n",
    "        tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.3)\n",
    "        tfidf_vect.fit(X_train)\n",
    "        X_train_tfidf = tfidf_vect.transform(X_train)\n",
    "        X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "        \n",
    "        model.fit(X_train_tfidf, Y_train)\n",
    "        out = model.predict(X_test_tfidf)\n",
    "\n",
    "        #print(len(out))\n",
    "        i = 0\n",
    "        for x in test_index:\n",
    "            preds[x] = out[i]\n",
    "            i += 1\n",
    "            \n",
    "        #print(preds)\n",
    "\n",
    "        n_iter += 1\n",
    "    accuracy = accuracy_score(Y, preds)\n",
    "    precision, recall, fscore, support = score(Y, preds)\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    # precision tp / (tp + fp)\n",
    "    # recall: tp / (tp + fn)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    accuracy = np.round(accuracy, 4)\n",
    "    precision[1] = np.round(precision[1], 4)\n",
    "    recall[1] = np.round(recall[1], 4)\n",
    "    fscore[1] = np.round(fscore[1], 4)\n",
    "    support[1] = np.round(support[1], 4)\n",
    "    \n",
    "    \n",
    "    return (accuracy, precision[1], recall[1], fscore[1], support[1])\n",
    "\n",
    "\n",
    "\n",
    "cls = 'CR-00-00-00-00'\n",
    "\n",
    "\n",
    "predict_by_class_tfidf(dfset, cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "0484da46afac2",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Download and Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "dfd2a43208cde",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:24, 16185.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip glove.6B.zip\n",
    "from tqdm import tqdm\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt', encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except ValueError:\n",
    "        pass\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "80878b118e62d",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## GloVe Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "effddb85e9eee",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint1 - Data Read Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1503/1503 [00:03<00:00, 488.96it/s]\n",
      " 26%|██▌       | 46/176 [00:00<00:00, 459.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Word Hit Rate(\\%) 99.58181372991224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:00<00:00, 529.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Word Hit Rate(\\%) 99.61077662227088\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "accuracy: 0.9034090909090909\n",
      "precision: [0.99275362 0.57894737]\n",
      "recall: [0.89542484 0.95652174]\n",
      "fscore: [0.94158076 0.72131148]\n",
      "support: [153  23]\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   42.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 20}\n"
     ]
    }
   ],
   "source": [
    "cls = 'CR-00-00-00-00'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import punkt\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Train and Test Split\n",
    "p = len(X) // 10 * 9\n",
    "train_text = X[:p]\n",
    "test_text = X[p:]\n",
    "\n",
    "\n",
    "print(\"Checkpoint1 - Data Read Complete\")\n",
    "\n",
    "\n",
    "hit = 0\n",
    "all_words = 0\n",
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    global hit, all_words\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    hit += len(M)\n",
    "    all_words += len(words)\n",
    "    \n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(train_text)]\n",
    "\n",
    "print('Mean Train Word Hit Rate(\\%)', hit / all_words * 100)\n",
    "hit = 0\n",
    "all_words = 0\n",
    "\n",
    "xtest_glove = [sent2vec(x) for x in tqdm(test_text)]\n",
    "print('Mean Test Word Hit Rate(\\%)', hit / all_words * 100)\n",
    "\n",
    "print('Checkpoint2 -Normalized Vector for Sentences are created')\n",
    "\n",
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xtest_glove = np.array(xtest_glove)\n",
    "\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced')\n",
    "\n",
    "train_target = Y[:p]\n",
    "test_target = Y[p:]\n",
    "\n",
    "model.fit(xtrain_glove, train_target)\n",
    "preds = model.predict(xtest_glove)\n",
    "\n",
    "print(preds)\n",
    "accuracy = accuracy_score(test_target, preds)\n",
    "precision, recall, fscore, support = score(test_target, preds)\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "\n",
    "\n",
    "params = {'C': [1,10,20,30,40]}\n",
    "grid_cv_lr = GridSearchCV(model,param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_lr.fit(xtrain_glove, train_target)\n",
    "print(grid_cv_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "36c031454b0fc",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## GloVE + Custom Logistic Regression on CR-00-00-00-00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "b4c41c9fe8b0c",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1679/1679 [00:03<00:00, 525.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1377\n",
      "1.0     302\n",
      "Name: CR-00-00-00-00, dtype: int64\n",
      "data set size 1679\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8785, 0.6219, 0.8278, 0.7102, 302)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "verbose = False\n",
    "    \n",
    "numdoc = defaultdict()\n",
    "\n",
    "classifier = defaultdict()\n",
    "\n",
    "    \n",
    "def predict_by_class_glove(dfset: defaultdict,cls: str) -> float:\n",
    "    preprocessing(dfset, cls)\n",
    "    tinydf = dfset[cls]\n",
    "    X = tinydf['full_text'].values\n",
    "    Y = tinydf[cls].values\n",
    "    X_glove = [sent2vec(x) for x in tqdm(X)]\n",
    "    X_glove = np.array(X_glove)\n",
    "\n",
    "    print('------------------------------------\\n')\n",
    "    labels = dfset[cls].iloc[:,2]\n",
    "    print(labels.value_counts(dropna=False))\n",
    "\n",
    "    # 10-fold separation with train and test \n",
    "    #kfold = KFold(n_splits=10)\n",
    "    kfold = KFold(n_splits=10)\n",
    "    print('data set size', len(X))\n",
    "    numdoc[cls] = len(X)\n",
    "    n_iter = 0\n",
    "    acc_list = []\n",
    "    pre_list = []\n",
    "    rec_list = []\n",
    "    fsc_list = []\n",
    "    sup_list = []\n",
    "\n",
    "    \n",
    "    preds = [0] * len(Y)\n",
    "\n",
    "    print('Checkpoint2 -Normalized Vector for Sentences are created')\n",
    "    \n",
    "\n",
    "\n",
    "    for train_index, test_index in kfold.split(X_glove, Y):\n",
    "\n",
    "        X_train, X_test = X_glove[train_index], X_glove[test_index] \n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Scikit-Learn\n",
    "        classifier[cls] = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced')\n",
    "        classifier[cls].fit(X_train, Y_train)\n",
    "        out = classifier[cls].predict(X_test)\n",
    "\n",
    "        #print(len(out))\n",
    "        i = 0\n",
    "        for x in test_index:\n",
    "            preds[x] = out[i]\n",
    "            i += 1\n",
    "            \n",
    "        #print(preds)\n",
    "\n",
    "        n_iter += 1\n",
    "    accuracy = accuracy_score(Y, preds)\n",
    "    precision, recall, fscore, support = score(Y, preds)\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    # precision tp / (tp + fp)\n",
    "    # recall:   tp / (tp + fn)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    accuracy = np.round(accuracy, 4)\n",
    "    precision[1] = np.round(precision[1], 4)\n",
    "    recall[1] = np.round(recall[1], 4)\n",
    "    fscore[1] = np.round(fscore[1], 4)\n",
    "    support[1] = np.round(support[1], 4)\n",
    "    \n",
    "    \n",
    "    return (accuracy, precision[1], recall[1], fscore[1], support[1])\n",
    "\n",
    "\n",
    "\n",
    "#cls = 'BE-00-00-00-00'\n",
    "cls = 'CR-00-00-00-00'\n",
    "predict_by_class_glove(dfset, cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqPjMWHLfCWn",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "6d16c3e0c6dac",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "# Entire Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLxJKWdxfQEs",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "1f636377bc915",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Build Models and Calculating Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJUvNbLprOTe",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "381e7a94d7c67",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/1848 [00:00<00:03, 531.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BE-00-00-00-00', 'BU-00-00-00-00', 'CO-00-00-00-00', 'CR-00-00-00-00',\n",
      "       'CR-01-00-00-00', 'CR-04-00-00-00', 'CR-06-00-00-00', 'CR-10-00-00-00',\n",
      "       'ED-00-00-00-00', 'ES-00-00-00-00', 'ES-01-00-00-00', 'ES-03-00-00-00',\n",
      "       'FA-00-00-00-00', 'FA-05-00-00-00', 'FA-06-00-00-00', 'FA-07-00-00-00',\n",
      "       'GO-00-00-00-00', 'HE-00-00-00-00', 'HO-00-00-00-00', 'HO-06-00-00-00',\n",
      "       'HO-09-00-00-00', 'IM-00-00-00-00', 'MO-00-00-00-00', 'MO-02-00-00-00',\n",
      "       'MO-07-00-00-00', 'MO-10-00-00-00', 'RI-00-00-00-00', 'TO-00-00-00-00',\n",
      "       'TR-00-00-00-00', 'TR-01-00-00-00', 'TR-02-00-00-00', 'TR-03-00-00-00',\n",
      "       'TR-04-00-00-00', 'TR-05-00-00-00', 'WO-00-00-00-00', 'WO-03-00-00-00'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [00:03<00:00, 517.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1821\n",
      "1.0      27\n",
      "Name: BE-00-00-00-00, dtype: int64\n",
      "data set size 1848\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 45/1590 [00:00<00:03, 447.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9226, 0.1329, 0.7778, 0.227, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:03<00:00, 515.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1497\n",
      "1.0      93\n",
      "Name: BU-00-00-00-00, dtype: int64\n",
      "data set size 1590\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1164 [00:00<00:02, 478.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9377, 0.483, 0.914, 0.632, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:02<00:00, 509.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1058\n",
      "1.0     106\n",
      "Name: CO-00-00-00-00, dtype: int64\n",
      "data set size 1164\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 49/1679 [00:00<00:03, 466.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.896, 0.4615, 0.8491, 0.598, 106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1679/1679 [00:03<00:00, 498.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1377\n",
      "1.0     302\n",
      "Name: CR-00-00-00-00, dtype: int64\n",
      "data set size 1679\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1393 [00:00<00:03, 376.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.8785, 0.6219, 0.8278, 0.7102, 302)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:02<00:00, 518.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1381\n",
      "1.0      12\n",
      "Name: CR-01-00-00-00, dtype: int64\n",
      "data set size 1393\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1402 [00:00<00:03, 401.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9088, 0.0248, 0.25, 0.0451, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1402/1402 [00:02<00:00, 524.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1389\n",
      "1.0      13\n",
      "Name: CR-04-00-00-00, dtype: int64\n",
      "data set size 1402\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 44/1404 [00:00<00:03, 385.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9058, 0.0458, 0.4615, 0.0833, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1404/1404 [00:02<00:00, 516.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1393\n",
      "1.0      11\n",
      "Name: CR-06-00-00-00, dtype: int64\n",
      "data set size 1404\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/1969 [00:00<00:03, 516.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9366, 0.0568, 0.4545, 0.101, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1969/1969 [00:03<00:00, 503.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1958\n",
      "1.0      11\n",
      "Name: CR-10-00-00-00, dtype: int64\n",
      "data set size 1969\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 49/1813 [00:00<00:03, 443.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9335, 0.0082, 0.0909, 0.015, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1813/1813 [00:03<00:00, 516.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1789\n",
      "1.0      24\n",
      "Name: ED-00-00-00-00, dtype: int64\n",
      "data set size 1813\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 57/1944 [00:00<00:03, 565.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.968, 0.2571, 0.75, 0.383, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1944/1944 [00:03<00:00, 529.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1866\n",
      "1.0      78\n",
      "Name: ES-00-00-00-00, dtype: int64\n",
      "data set size 1944\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/1876 [00:00<00:03, 555.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9208, 0.3155, 0.8333, 0.4577, 78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1876/1876 [00:03<00:00, 526.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1866\n",
      "1.0      10\n",
      "Name: ES-01-00-00-00, dtype: int64\n",
      "data set size 1876\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 54/1992 [00:00<00:03, 539.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9403, 0.0278, 0.3, 0.0508, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:03<00:00, 524.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1979\n",
      "1.0      13\n",
      "Name: ES-03-00-00-00, dtype: int64\n",
      "data set size 1992\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/2042 [00:00<00:03, 524.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9342, 0.053, 0.5385, 0.0966, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2042/2042 [00:03<00:00, 520.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1685\n",
      "1.0     357\n",
      "Name: FA-00-00-00-00, dtype: int64\n",
      "data set size 2042\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/2011 [00:00<00:03, 551.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9119, 0.6928, 0.8908, 0.7794, 357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2011/2011 [00:03<00:00, 529.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    2001\n",
      "1.0      10\n",
      "Name: FA-05-00-00-00, dtype: int64\n",
      "data set size 2011\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/1791 [00:00<00:03, 539.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9423, 0.0508, 0.6, 0.0938, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1791/1791 [00:03<00:00, 529.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1781\n",
      "1.0      10\n",
      "Name: FA-06-00-00-00, dtype: int64\n",
      "data set size 1791\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/1968 [00:00<00:03, 514.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9324, 0.0336, 0.4, 0.062, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1968/1968 [00:03<00:00, 533.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1927\n",
      "1.0      41\n",
      "Name: FA-07-00-00-00, dtype: int64\n",
      "data set size 1968\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 42/1517 [00:00<00:03, 417.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.8786, 0.1133, 0.7073, 0.1953, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1517/1517 [00:03<00:00, 496.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1504\n",
      "1.0      13\n",
      "Name: GO-00-00-00-00, dtype: int64\n",
      "data set size 1517\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 55/1900 [00:00<00:03, 546.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9242, 0.0364, 0.3077, 0.065, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [00:03<00:00, 521.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1778\n",
      "1.0     122\n",
      "Name: HE-00-00-00-00, dtype: int64\n",
      "data set size 1900\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 57/2132 [00:00<00:03, 566.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9605, 0.6343, 0.9098, 0.7475, 122)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2132/2132 [00:04<00:00, 498.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1582\n",
      "1.0     550\n",
      "Name: HO-00-00-00-00, dtype: int64\n",
      "data set size 2132\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 57/1662 [00:00<00:02, 563.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9536, 0.902, 0.92, 0.9109, 550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1662/1662 [00:03<00:00, 546.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1628\n",
      "1.0      34\n",
      "Name: HO-06-00-00-00, dtype: int64\n",
      "data set size 1662\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/1653 [00:00<00:02, 559.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9296, 0.1732, 0.6471, 0.2733, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1653/1653 [00:02<00:00, 554.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1626\n",
      "1.0      27\n",
      "Name: HO-09-00-00-00, dtype: int64\n",
      "data set size 1653\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/1964 [00:00<00:03, 556.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9546, 0.2333, 0.7778, 0.359, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1964/1964 [00:03<00:00, 520.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1928\n",
      "1.0      36\n",
      "Name: IM-00-00-00-00, dtype: int64\n",
      "data set size 1964\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 46/1429 [00:00<00:03, 448.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9684, 0.3523, 0.8611, 0.5, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1429/1429 [00:02<00:00, 539.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1063\n",
      "1.0     366\n",
      "Name: MO-00-00-00-00, dtype: int64\n",
      "data set size 1429\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 56/1949 [00:00<00:03, 552.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.8509, 0.6727, 0.8142, 0.7367, 366)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [00:03<00:00, 536.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1937\n",
      "1.0      12\n",
      "Name: MO-02-00-00-00, dtype: int64\n",
      "data set size 1949\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 50/1129 [00:00<00:02, 495.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9477, 0.05, 0.4167, 0.0893, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1129/1129 [00:02<00:00, 548.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1116\n",
      "1.0      13\n",
      "Name: MO-07-00-00-00, dtype: int64\n",
      "data set size 1129\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 49/1106 [00:00<00:02, 488.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9336, 0.0921, 0.5385, 0.1573, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1106/1106 [00:01<00:00, 560.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1095\n",
      "1.0      11\n",
      "Name: MO-10-00-00-00, dtype: int64\n",
      "data set size 1106\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 45/1396 [00:00<00:03, 447.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9168, 0.0449, 0.3636, 0.08, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1396/1396 [00:02<00:00, 537.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1374\n",
      "1.0      22\n",
      "Name: RI-00-00-00-00, dtype: int64\n",
      "data set size 1396\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 47/1257 [00:00<00:02, 468.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.861, 0.0275, 0.2273, 0.049, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1257/1257 [00:02<00:00, 575.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1027\n",
      "1.0     230\n",
      "Name: TO-00-00-00-00, dtype: int64\n",
      "data set size 1257\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 57/2006 [00:00<00:03, 552.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.8536, 0.565, 0.8696, 0.6849, 230)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2006/2006 [00:03<00:00, 523.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1746\n",
      "1.0     260\n",
      "Name: TR-00-00-00-00, dtype: int64\n",
      "data set size 2006\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 54/1827 [00:00<00:03, 534.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9482, 0.7407, 0.9231, 0.8219, 260)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1827/1827 [00:03<00:00, 514.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1805\n",
      "1.0      22\n",
      "Name: TR-01-00-00-00, dtype: int64\n",
      "data set size 1827\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 51/1819 [00:00<00:03, 495.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics (0.9507, 0.1667, 0.7727, 0.2742, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1819/1819 [00:03<00:00, 515.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "0.0    1790\n",
      "1.0      29\n",
      "Name: TR-02-00-00-00, dtype: int64\n",
      "data set size 1819\n",
      "Checkpoint2 -Normalized Vector for Sentences are created\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "class_list = df.columns[2:]\n",
    "print(class_list)\n",
    "verbose = False\n",
    "stat_dict = defaultdict() \n",
    "for cls in class_list:\n",
    "    preprocessing(dfset, cls)\n",
    "    ret = predict_by_class_glove(dfset, cls)\n",
    "    stat_dict[cls] = ret \n",
    "    print('statistics' , ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "1342ba687f607",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "6611849a9aa39",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install prettytable\n",
    "from prettytable import PrettyTable\n",
    "t = PrettyTable([\"class\", \"accuracy\", \"precision\", \"recall\", \"F1 score\", \"support\", \"|documents|\"])\n",
    "#t.align[\"class\"] = \"r\"\n",
    "t.align[\"accuracy\"] = \"r\"\n",
    "t.align[\"precision\"] = \"r\"\n",
    "t.align[\"recall\"] = \"r\"\n",
    "t.align[\"F1 score\"] = \"r\"\n",
    "t.align[\"support\"] = \"r\"\n",
    "for k,v in stat_dict.items():\n",
    "    t.add_row([k, v[0], v[1], v[2], v[3], v[4], numdoc[k]])\n",
    "    \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1tu4jFOrOaf",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "ba74459e4e83b",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Plotting for Top10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4sGK9DsrOhR",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "120b319cdd3d",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [],
   "source": [
    "#for k,v in accuracy_dict.items():\n",
    "#    print(k,v)\n",
    "#sys.exit()\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Example data\n",
    "y_pos = np.arange(10)\n",
    "error = 0 \n",
    "\n",
    "recall_dict = defaultdict()\n",
    "for k,v in stat_dict.items():\n",
    "    recall_dict[k] = v[2]\n",
    "\n",
    "sorted_x = sorted(recall_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "topcat_dict = collections.OrderedDict(sorted_x)\n",
    "#print(topcat_dict)\n",
    "\n",
    "keyList = []\n",
    "valList = []\n",
    "for kv in topcat_dict.items():\n",
    "    keyList.append(kv[0])\n",
    "    valList.append(kv[1])\n",
    "\n",
    "ax.barh(y_pos[:10], valList[:10], xerr=error, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(keyList[:10])\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_title('Top10 Recall Scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "3128d732afee1",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Bottom 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "7631c8aa247f3",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for k,v in accuracy_dict.items():\n",
    "#    print(k,v)\n",
    "#sys.exit()\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Example data\n",
    "y_pos = np.arange(10)\n",
    "error = 0 \n",
    "\n",
    "recall_dict = defaultdict()\n",
    "for k,v in stat_dict.items():\n",
    "    recall_dict[k] = v[2]\n",
    "    \n",
    "sorted_x = sorted(recall_dict.items(), key=lambda kv: kv[1])\n",
    "topcat_dict = collections.OrderedDict(sorted_x)\n",
    "#print(topcat_dict)\n",
    "\n",
    "keyList = []\n",
    "valList = []\n",
    "for kv in topcat_dict.items():\n",
    "    keyList.append(kv[0])\n",
    "    valList.append(kv[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.barh(y_pos[:10], valList[:10], xerr=error, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(keyList[:10])\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_title('Bottom 10 Recall Scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "b32f8fe86d67c",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "## Recall Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": true,
     "current_version": 0,
     "id": "c55860008c8bc",
     "named_versions": [],
     "output_hidden": true,
     "show_versions": false,
     "source_hidden": true,
     "versions": []
    }
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "\n",
    "recall_dict = defaultdict()\n",
    "for k,v in stat_dict.items():\n",
    "    recall_dict[k] = v[2]\n",
    "\n",
    "\n",
    "recall_list = []\n",
    "for k,v in recall_dict.items():\n",
    "    recall_list.append(v*100)\n",
    "   \n",
    "d = {'Recall': recall_list}\n",
    "tinydf = pd.DataFrame(data=d)\n",
    "\n",
    "\n",
    "\n",
    "hist = tinydf.hist(edgecolor='black', bins = [0,10,20,30,40,50,60,70,80,90,100])\n",
    "pl.title(\"Recall Distribution\")\n",
    "pl.xlabel(\"Recall Score(%)\")\n",
    "pl.ylabel(\"Number of Classes\")\n",
    "print(tinydf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6opsKxImIb5b",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "4b997c0e2f005",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    }
   },
   "source": [
    "# Custom Input Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qro-3iB4IiEy",
    "janus": {
     "all_versions_showing": false,
     "cell_hidden": false,
     "current_version": 0,
     "id": "5f2ad812917d3",
     "named_versions": [],
     "output_hidden": false,
     "show_versions": false,
     "source_hidden": false,
     "versions": []
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = \"How do I get my mom's license taken away. My mom is 66, on disability for multiple sclerosis. She's been unable to work for about a decade. She has cataracts. She has neuropathy. She has 0 reaction time. She has had a fender bender on every single corner of her last car, which my brother then totaled. She also has no night vision. She also falls asleep all the time. ALMOST like like narcolepsy. It's mostly her overextending herself, but she will nod off driving or sleep in parking lots til she feels ok. She also has lymphedema in her legs which are swollen enough to impede driving. The last year she was driving she received 19 red light tickets. She agreed not to drive. And the insurance paid for her car. Now she's bought a new one, about 6 months later. Our relationship is terrible. I hate her. But I want her licence taken away before she kills or cripples someone(s). I'm no contact with her, but my brother still tries and he cares about this a lot. I've spoken with the DMV IN MY state, not very helpful. Can i contact her insurance? Do I contact the police? Has this happened to anyone\"\n",
    "\n",
    "print(text)\n",
    "input = sent2vec(text)\n",
    "input = np.array(input)\n",
    "\n",
    "predictions = defaultdict() \n",
    "prob = defaultdict()\n",
    "for cls in class_list:\n",
    "    predictions[cls] = classifier[cls].predict([input])\n",
    "    prob[cls] = classifier[cls].predict_proba([input])\n",
    "for k,v in predictions.items():   \n",
    "    if v > 0:\n",
    "        print(k, v, end = ' ')\n",
    "        print(np.round(prob[k][0][1], 4))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNEs8q1mzt8F3PvZ4WJe7iF",
   "name": "legal_issue_classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "janus": {
   "filepaths": [
    [
     "ccbc57fe",
     1582755372683,
     1583617048644
    ]
   ],
   "janus_markers": [
    {
     "ids": [
      "fbc1e35bd1c07",
      "b4140f133d1e6"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "46f3ebdce3ec5"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "da6bfdef8ea13"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "455af60adbcad"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "11e5448bf4137"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "722be740702ee"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "dfd2a43208cde"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "8dd4a61345312"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "381e7a94d7c67"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "6611849a9aa39"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "120b319cdd3d"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "7631c8aa247f3"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    },
    {
     "ids": [
      "c55860008c8bc"
     ],
     "markerName": "Hidden Cells",
     "showing": false
    }
   ],
   "track_history": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
